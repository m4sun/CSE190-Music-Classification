{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraies \n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display as ld\n",
    "import random\n",
    "import pickle, itertools, sklearn, pandas as pd, seaborn as sn\n",
    "from scipy.spatial import distance\n",
    "from scipy import spatial\n",
    "import csv\n",
    "from tqdm import tqd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.layers import Input, Dense, InputLayer, InputLayer, Concatenate, Flatten, Reshape, Lambda, Embedding, dot\n",
    "from keras.layers import Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.layers import BatchNormalization, GlobalMaxPool1D, Activation, concatenate\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pairs of ALL audio with genres from Metadata list\n",
    "\n",
    "# open metadata file\n",
    "tsv_file = open(\"./mtg/data/raw_30s_cleantags.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "track_genre_dict = {}\n",
    "for row in read_tsv:\n",
    "    # print(row)\n",
    "    name = row[0][6:len(row[0])]     # cut 'track_'\n",
    "    if name != 'ID': \n",
    "        for c in name:               # cut leading 0s\n",
    "            if c == '0':\n",
    "                name = name[1:]\n",
    "            else:\n",
    "                break\n",
    "        name = name + '.npy'\n",
    "    \n",
    "        genre = []\n",
    "        for ele in row:\n",
    "            if 'genre' in ele:\n",
    "                genre.append(ele[8:]) # cut 'genre__'\n",
    "\n",
    "        track_genre_dict[name] = genre\n",
    "    \n",
    "# track_genre = track_genre[1:] # cut first one, tag 'ID, Genre'\n",
    "# print(track_genre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract songs from different genres \n",
    "\n",
    "# open spectrum foler\n",
    "dir = os.getcwd()+\"/mel_spec/\"\n",
    "# print(dir)\n",
    "\n",
    "spectrums = []\n",
    "spectrums_filename = []\n",
    "y_col = []\n",
    "\n",
    "for root, dirs, files in os.walk(dir, topdown=False) :\n",
    "    # print(files)\n",
    "    for name in files:\n",
    "        # print(name)\n",
    "        if name in track_genre_dict:\n",
    "            fullname = os.path.join(root, name)\n",
    "            # print(fullname)\n",
    "        \n",
    "            if fullname.find(\".npy\") != -1 :\n",
    "                genre_list = track_genre_dict.get(name)\n",
    "                if ('hiphop' in genre_list and 'instrumentalhiphop' not in genre_list and \n",
    "                   'rock' not in genre_list and 'poprock' not in genre_list and\n",
    "                   'electronic' not in genre_list):\n",
    "                    spectrums.append(fullname)\n",
    "                    spectrums_filename.append(name)\n",
    "                    y_col.append(0)\n",
    "                elif ('rock' in genre_list and 'instrumentalrock' not in genre_list and \n",
    "                      'pop' not in genre_list and 'ambient' not in genre_list and \n",
    "                      'southernrock' not in genre_list):\n",
    "                    spectrums.append(fullname)\n",
    "                    spectrums_filename.append(name)\n",
    "                    y_col.append(1)\n",
    "                elif 'classical' in genre_list and len(genre_list) == 1 :\n",
    "                    spectrums.append(fullname)\n",
    "                    spectrums_filename.append(name)\n",
    "                    y_col.append(2)\n",
    "                # else:\n",
    "                    # y_col.append(3)\n",
    "\n",
    "y_col = np.array(y_col)\n",
    "spectrums = np.array(spectrums)\n",
    "spectrums_filename = np.array(spectrums_filename)\n",
    "\n",
    "# print(spectrums)\n",
    "# print(len(y_col))\n",
    "# print(y_col)\n",
    "\n",
    "# Generate positive samples\n",
    "\n",
    "spec1 = spectrums[np.where(y_col==0)]    \n",
    "spec2 = spectrums[np.where(y_col==1)]\n",
    "spec3 = spectrums[np.where(y_col==2)]\n",
    "\n",
    "# spec1 = spectrums_filename[np.where(y_col==0)]    \n",
    "# spec2 = spectrums_filename[np.where(y_col==1)]\n",
    "# spec3 = spectrums_filename[np.where(y_col==2)]\n",
    "\n",
    "print(len(spec1))   \n",
    "print(len(spec2))   \n",
    "print(len(spec3))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking genres of songs we pick\n",
    "\n",
    "# for name in spec2:\n",
    "#     genre_list = track_genre_dict.get(name)\n",
    "#     print(name)\n",
    "#     print(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate positive and negative samples\n",
    "\n",
    "# Test spectrums, last 10 spec\n",
    "test_1_spec = spec1[-10:]\n",
    "test_2_spec = spec2[-10:]\n",
    "test_3_spec = spec3[-10:]\n",
    "\n",
    "# Save test data\n",
    "f = open(os.getcwd()+\"/test_specs.pkl\", 'wb')\n",
    "pickle.dump([test_1_spec, test_2_spec, test_3_spec], f)\n",
    "f.close()\n",
    "\n",
    "# Train spectrums, first 30 spec\n",
    "train_1_spec = spec1[:30]\n",
    "train_2_spec = spec2[:30]\n",
    "train_3_spec = spec3[:30]\n",
    "\n",
    "# print(test_pop_spec)\n",
    "# print(pop_spec)\n",
    "\n",
    "# Generate positive samples\n",
    "positive1 = list(itertools.combinations(spec1, 2)) # all pop file name pairs\n",
    "positive2 = list(itertools.combinations(spec2, 2))\n",
    "positive3 = list(itertools.combinations(spec3, 2))\n",
    "\n",
    "# print(positive_pop)\n",
    "\n",
    "# Generate negative samples\n",
    "negative1 = list(itertools.product(spec1, spec2))\n",
    "negative2 = list(itertools.product(spec1, spec3))\n",
    "negative3 = list(itertools.product(spec2, spec3))\n",
    "\n",
    "print(len(positive1))\n",
    "print(len(positive2))\n",
    "print(len(positive3))\n",
    "print(len(negative1))\n",
    "print(len(negative2))\n",
    "print(len(negative3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify spectrums' SIZE\n",
    "\n",
    "lis = list(spec1) + list(spec2) + list(spec3)\n",
    "# print(len(lis))\n",
    "lshape = []\n",
    "for fname in lis :\n",
    "    mspec = np.load(fname)\n",
    "    lshape.append(mspec.shape[1])\n",
    "        \n",
    "print(min(lshape))\n",
    "\n",
    "lowest_shape = min(lshape) - 1\n",
    "print(lowest_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine and add labels to all sample pairs \n",
    "\n",
    "def add_pairs(x, X1, X2, Y, f, label, num):\n",
    "    counter = 0\n",
    "    for fname in x :\n",
    "        if counter == num:\n",
    "            break\n",
    "\n",
    "        mspec = np.load(fname[0])\n",
    "        mspec = mspec[:, :f]\n",
    "        X1.append(mspec)\n",
    "        mspec = np.load(fname[1])\n",
    "        mspec = mspec[:, :f]\n",
    "        X2.append(mspec)\n",
    "        Y.append(label)\n",
    "\n",
    "        counter += 1\n",
    "    return X1, X2, Y\n",
    "\n",
    "spec_X1 = []\n",
    "spec_X2 = []\n",
    "spec_y = []\n",
    "\n",
    "num_pos = 500\n",
    "num_neg = 500\n",
    "\n",
    "spec_X1, spec_X2, spec_y = add_pairs(positive1, spec_X1, spec_X2, spec_y, lowest_shape, 1, num_pos)\n",
    "spec_X1, spec_X2, spec_y = add_pairs(positive2, spec_X1, spec_X2, spec_y, lowest_shape, 1, num_pos)\n",
    "spec_X1, spec_X2, spec_y = add_pairs(positive3, spec_X1, spec_X2, spec_y, lowest_shape, 1, num_pos)\n",
    "\n",
    "spec_X1, spec_X2, spec_y = add_pairs(negative1, spec_X1, spec_X2, spec_y, lowest_shape, 0, num_neg)\n",
    "spec_X1, spec_X2, spec_y = add_pairs(negative2, spec_X1, spec_X2, spec_y, lowest_shape, 0, num_neg)\n",
    "spec_X1, spec_X2, spec_y = add_pairs(negative3, spec_X1, spec_X2, spec_y, lowest_shape, 0, num_neg)\n",
    "\n",
    "# Reshape the input data set\n",
    "\n",
    "spec_y = np.array(spec_y)\n",
    "spec_X1 = np.array(spec_X1)\n",
    "spec_X2 = np.array(spec_X2)\n",
    "\n",
    "spec_X1 = spec_X1.reshape((len(spec_y), 96, lowest_shape)) # spect of size \n",
    "spec_X2 = spec_X2.reshape((len(spec_y), 96, lowest_shape))\n",
    "\n",
    "spec_X1 = 1 - spec_X1/255\n",
    "spec_X2 = 1 - spec_X2/255\n",
    "\n",
    "print(\"Song Spec data : \", spec_X1.shape, spec_X2.shape, spec_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SNN model and save model\n",
    "\n",
    "def contrastive_loss(y, preds, margin=1):\n",
    "    # explicitly cast the true class label data type to the predicted\n",
    "    # class label data type (otherwise we run the risk of having two\n",
    "    # separate data types, causing TensorFlow to error out)\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "    # calculate the contrastive loss between the true labels and\n",
    "    # the predicted labels\n",
    "    squaredPreds = K.square(preds)\n",
    "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
    "    # return the computed contrastive loss to the calling function\n",
    "    return loss\n",
    "\n",
    "def train_songs_encoder(X1, X2, y) :\n",
    "    # hyper-parameters\n",
    "    n_filters = 64\n",
    "    filter_width = 3\n",
    "    dilation_rates = [2**i for i in range(8)] \n",
    "    \n",
    "    history_seq = Input((96, lowest_shape))\n",
    "    x = history_seq\n",
    "    \n",
    "    skips = []\n",
    "    count = 0\n",
    "    for dilation_rate in dilation_rates:\n",
    "        x = Conv1D(filters=n_filters,\n",
    "                    kernel_size=filter_width, \n",
    "                    padding='causal',\n",
    "                    dilation_rate=dilation_rate, activation='relu', name=\"conv1d_dilation_\"+str(dilation_rate))(x)\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "    out = Conv1D(32, 16, padding='same')(x)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('tanh')(out)\n",
    "    out = GlobalMaxPool1D()(out)\n",
    "    \n",
    "    model = Model(history_seq, out)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    input1 = Input((96, lowest_shape), name=\"Positive Input\")\n",
    "    input2 = Input((96, lowest_shape), name=\"Negative Input\")\n",
    "\n",
    "\n",
    "    # Create left and right twin encoded models\n",
    "    left_model = model(input1)\n",
    "    right_model = model(input2)\n",
    "    \n",
    "    # concatenate layer\n",
    "    concat = concatenate([left_model, right_model], axis=1)\n",
    "    siamese_net = Model([input1, input2], concat)\n",
    "    siamese_net.compile(optimizer='adam', loss=contrastive_loss)\n",
    "\n",
    "    print(siamese_net.summary())\n",
    "\n",
    "    # Fit model\n",
    "    siamese_net.fit([X1, X2], y, epochs=35, batch_size=256, verbose=1)\n",
    "\n",
    "    model.save(os.getcwd()+\"/song_encoder.h5\")\n",
    "    siamese_net.save(os.getcwd()+\"/song_siamese_model.h5\")\n",
    "    \n",
    "    return model, siamese_net\n",
    "\n",
    "\n",
    "# train model\n",
    "model, siamese_model = train_songs_encoder(spec_X1, spec_X2, spec_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "\n",
    "# Load models\n",
    "model = load_model(os.getcwd()+\"/song_encoder.h5\", compile= False)\n",
    "siamese_model = load_model(os.getcwd()+\"/song_siamese_model.h5\", compile= False)\n",
    "\n",
    "# Load test data\n",
    "f = open(os.getcwd()+\"/test_specs.pkl\", 'rb')\n",
    "# f = open(os.getcwd()+\"/test(train)_specs.pkl\", 'rb')\n",
    "test_1_spec, test_2_spec, test_3_spec = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# test_1_spec = pop_spec[-10:]\n",
    "# test_2_spec = electr_spec[-10:]\n",
    "# test_3_spec = classic_spec[-10:]\n",
    "\n",
    "# Read Test files\n",
    "names = list(test_1_spec) + list(test_2_spec) + list(test_3_spec)\n",
    "\n",
    "test_spec = []\n",
    "for i in range(len(names)) :   \n",
    "    s = np.load(names[i])\n",
    "    s = s[:, :lowest_shape]\n",
    "    test_spec.append(s)\n",
    "\n",
    "r,c = test_spec[0].shape\n",
    "\n",
    "# print(test_spec[0].shape)\n",
    "\n",
    "test_spec = np.array(test_spec)\n",
    "test_spec = test_spec.reshape((len(test_spec), r,c))\n",
    "names = [x.split(\"/\")[-1] for x in names]\n",
    "\n",
    "test_spec = 1 - test_spec/255\n",
    "\n",
    "# Set labels for test set\n",
    "print(test_spec.shape)\n",
    "\n",
    "l_1 = list(np.full(shape=10, fill_value=0, dtype=np.int))\n",
    "l_2 = list(np.full(shape=10, fill_value=1, dtype=np.int))\n",
    "l_3 = list(np.full(shape=10, fill_value=2, dtype=np.int))\n",
    "\n",
    "test_spec_label = l_1 + l_2 + l_3\n",
    "test_spec_label = np.array(test_spec_label)\n",
    "\n",
    "print(test_spec_label.shape)\n",
    "\n",
    "# Get test data predict vectors\n",
    "pred_frame = model.predict(test_spec)\n",
    "\n",
    "print(pred_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate arruracy \n",
    "\n",
    "sim_mat = np.zeros((len(test_spec), len(test_spec)))\n",
    "pred = []\n",
    "\n",
    "for i in tqdm(range(len(test_spec))) :\n",
    "\n",
    "    curr = test_spec[i:i+1]\n",
    "    sim = model.predict(curr)\n",
    "    # compare each test data vector distance to trained data set vector\n",
    "    sim = [1 - spatial.distance.cosine(sim[0], pred_frame[x]) for x in range(len(pred_frame))]\n",
    "    sim = np.array(sim)\n",
    "    sim[sim<0] = 0\n",
    "    ind = np.copy(test_spec_label)\n",
    "    # Sort labels based on similarity scores\n",
    "    ind = [x for _,x in sorted(zip(sim, ind))]\n",
    "    ind = ind[::-1] # reverse the list, higher score to lower score\n",
    "    ind = ind[:21]\n",
    "    # Count the number of predictions to each genre\n",
    "    u, f = np.unique(ind, return_counts= True)\n",
    "    # Pick the one with the most appearence from predictions\n",
    "    best = u[np.argmax(f)]\n",
    "    pred.append(best)\n",
    "    sim_mat[i] = sim\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(test_spec_label, pred, normalize= 'true')\n",
    "print(\"Accuracy on testset : \", np.trace(conf_mat)/np.sum(conf_mat))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "music_genre_dict = {0:'hiphop', 1:'rock', 2:'classical'}\n",
    "u = np.unique(test_spec_label)\n",
    "\n",
    "conf_mat = pd.DataFrame(conf_mat, columns= [music_genre_dict[x] for x in u], index= [music_genre_dict[x] for x in u])\n",
    "plt.figure(figsize = (15,10))\n",
    "sn.heatmap(conf_mat, annot=True, annot_kws={\"size\": 10}, cmap='jet')\n",
    "plt.tick_params(labelsize=8)\n",
    "plt.xticks(rotation= 60)\n",
    "plt.title(\"Music classification\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "# plt.savefig(os.getcwd()+\"/ConfusionMatrix_test.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
